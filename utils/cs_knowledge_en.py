import json
import sys
import json 
import random 
import os 
import argparse
import random
import time
from config import keys, Qwen_Max

random.seed(int(time.time()))
os.environ["QWEN_API_KEY"] = random.choice(keys)
sys.path.append("./")

def qwenmax_eval(question, ans_en, response, qwenmax):
    prompt = f'''
You are an objective and rigorous question-answering evaluation assistant. Next, I will provide the following items:

Question: A knowledge question.
Answer: The correct answer to the question.
Model Response: The actual response generated by a model for the question.

Please analyze and evaluate according to the following requirements:

Determine whether the "model response" is consistent with the answer. If the model response is an alias for the answer, it is also marked as correct.

Output format: True/False [Simplified explanation]
Example: True The model response is semantically consistent with the answer.

Question: {question}
Answer: {ans_en}
Model response: {response}
  ***
  '''
    for i in range(10):
        messages = [
            {
                "role": "user",
                "content": prompt
            }
        ]
        print(messages)
        text = qwenmax(messages)["text"]
        if text.startswith("True"):
          return True, text
        elif text.startswith("False"):
          return False, text
    return False, text

def part_correct(ans_zh, response):
  assert '·' in ans_zh
  answer_parts = ans_zh.split('·')
  for part in answer_parts:
      if part.strip() in response:  
          return True
  return False

def qwenmax_eval_json(input_json, output_json):
    ref_json = '../json/cs_knowledge_en.json'
    with open(ref_json, "r") as f:
        ref = json.load(f)
    with open(input_json, "r", encoding = 'utf-8') as f:
        try:
            data = json.load(f)
        except:
            f.seek(0)
            data = [json.loads(line) for line in f]

    instances = []
    correct_num = 0
    if os.path.exists(output_json):
      with open(output_json, "r") as f:
        finished = json.load(f)
      for instance in finished:
        instances.append(instance)
        if instance['Correct']:
          correct_num += 1

    qwenmax = Qwen_Max(model_name="qwen-max-2025-01-25")
    
    for instance in data[len(instances):]:
      index = int(instance['Qid'].split('-')[1])
      ans_en = ref[index]['Answer']
      category = ref[index]['Category']
      response = instance['Response']
      if ans_en.lower() in response.lower():
        instances.append({
          'Qid': instance['Qid'],
          'Response': response,
          'Category': category,
          'Correct': True,
          'Explain': f"Answer in the model response: {ans_en}"
        })
        correct_num += 1
      else:
        correct, explain = qwenmax_eval(ref[index]['Question'], ans_en, response, qwenmax)
        instances.append({
          'Qid': instance['Qid'],
          'Response': response,
          'Category': category,
          'Correct': correct,
          'Explain': explain
        })
        correct_num += correct
      with open(output_json, 'w+', encoding = 'utf-8') as outf:
        json.dump(instances, outf, ensure_ascii=False, indent = 4)
    
    print(f"Avg Accuracy: {correct_num/len(instances)}")


if __name__ == "__main__": 
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_json", type=str)
    parser.add_argument("--output_json", type=str)
    args = parser.parse_args()

    qwenmax_eval_json(args.input_json, args.output_json)

